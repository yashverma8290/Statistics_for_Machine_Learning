{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854d5b3d-83ca-4ceb-9f33-d90386c7a2e6",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392e329-50e3-40c8-997e-55dcdd7e7fe5",
   "metadata": {},
   "source": [
    "Standardization is a preprocessing technique in machine learning that transforms data to have a mean of 0 and a standard deviation of 1. It is particularly useful when features in a dataset have different scales, which can negatively impact models that rely on distance-based calculations, such as K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Principal Component Analysis (PCA). Standardization ensures that all features contribute equally to the model, preventing dominant effects from features with large numerical values.\n",
    "\n",
    "In the given code, StandardScaler from sklearn.preprocessing is used to standardize a dataset containing two numerical features. The dataset consists of values where one column represents smaller numerical values, such as age, while the other represents much larger values, such as income. The transformation follows the Z-score normalization formula: Z=(X-u)/sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653122d-263c-41c6-a354-2f471b00e177",
   "metadata": {},
   "source": [
    "where \n",
    "ùëã\n",
    "X is the original value, \n",
    "ùúá\n",
    "Œº is the mean of the feature, and \n",
    "ùúé\n",
    "œÉ is its standard deviation. This formula ensures that the transformed data has a mean of 0 and a standard deviation of 1, making the data more suitable for machine learning algorithms.\n",
    "\n",
    "The fit_transform() function first calculates the mean and standard deviation for each feature, then applies the transformation. As a result, the standardized values reflect how far each data point is from the mean in terms of standard deviations. This adjustment allows models to process data more effectively, particularly when features have vastly different ranges. Standardization does not change the shape of the data distribution; rather, it shifts the values to be centered around zero and ensures uniform variance. This process improves the stability and performance of machine learning models by creating a level playing field for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7864f22-d88a-415b-b97f-a0b2df1ca251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.34164079 -0.9351438 ]\n",
      " [-0.4472136  -0.72733407]\n",
      " [ 0.4472136   0.05195243]\n",
      " [ 1.34164079  1.61052543]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[20, 10000], [40, 50000], [60, 200000], [80, 500000]])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beeb53e-07a4-4140-ab22-b6e6a4024550",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d5189-7de6-48e0-b2a5-621f29fafadf",
   "metadata": {},
   "source": [
    "Normalization is a crucial data preprocessing technique in machine learning that transforms numerical features into a common scale, typically within a fixed range like [0,1] or [-1,1]. Unlike standardization, which centers the data around a mean of 0 and a standard deviation of 1, normalization preserves the original relationships between data points while ensuring that all values fall within a defined range. This is particularly useful for machine learning models that rely on gradient-based optimization, such as neural networks, as it prevents large numerical values from dominating smaller ones. The most commonly used normalization method is Min-Max Scaling, which applies the formula X'=(X-Xmin)/(Xmax-Xmin) where \n",
    "X is the original value. This transformation ensures that the smallest value in the dataset maps to 0, the largest maps to 1, and all other values are proportionally scaled in between.\n",
    "\n",
    "Normalization is essential in machine learning models that use distance-based calculations, such as K-Means Clustering, K-Nearest Neighbors (KNN), and Principal Component Analysis (PCA), where maintaining the relative scale of features is important. It also significantly improves the convergence speed of deep learning models by preventing extremely large values from affecting weight updates in neural networks. In practice, normalization is implemented using libraries like Scikit-learn, where the MinMaxScaler function can be used to automatically rescale data. By applying normalization, we ensure that different features contribute equally to the model, leading to more stable, efficient, and accurate predictions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718e26e2-179b-4f74-8cb2-8916c8682bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [0.33333333 0.08163265]\n",
      " [0.66666667 0.3877551 ]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset with two features (e.g., age and income)\n",
    "data = np.array([[20, 10000], [40, 50000], [60, 200000], [80, 500000]])\n",
    "\n",
    "# Create a MinMaxScaler instance (scales data between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Print the transformed values\n",
    "print(normalized_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a2b2e-eb11-49cc-bad3-251ba2093133",
   "metadata": {},
   "source": [
    "The given code demonstrates how to apply Min-Max Normalization to a dataset using the MinMaxScaler from Scikit-learn. The dataset consists of two features: an arbitrary numerical feature (such as age) and another feature with a significantly larger range (such as income). Since machine learning models can be sensitive to the scale of input features, normalization ensures that all values are mapped to a common range‚Äîtypically between 0 and 1‚Äîwhich helps models learn more efficiently and prevents dominance by larger numerical values.\n",
    "\n",
    "In this code, a MinMaxScaler instance is created, which applies the transformation using the formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c8438-5dd5-458e-aefa-8cbfa4d209c2",
   "metadata": {},
   "source": [
    " This ensures that the minimum value becomes 0, the maximum value becomes 1, and all other values are proportionally scaled within this range.\n",
    "\n",
    "After applying fit_transform(), the transformed dataset contains values between 0 and 1 for both features. This transformation is particularly beneficial for algorithms like K-Nearest Neighbors (KNN), Neural Networks, and Gradient Descent-based models, which perform better when input features have similar numerical ranges. By normalizing the dataset, the model can make fair comparisons between different features without being biased toward features with larger numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60105648-0099-402c-b6b9-b3ebb326d569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
